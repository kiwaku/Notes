Mobiz notes for my learning


Understanding the Langchain documentation
Language models course
Deep learning course


Base LLM:
Predicts next word


Instruction Tuned LLM:
Tries to follow instructions


RLHF: learning with human feedback


Specify output structures


Summary, name, output, JSON


Giving out instructions for chatGPT, extremely clear text inputs


Words, sentence or character limit


Iterative Prompt development
Idea, analysis, experiment, error analysis


Understanding Sentiment,
Understanding emotion from text
Extracting a list of topics


LLMs + custom data
Connecting large language models


Varying the GPT temperature


Probability statistics, linear algebra


Covid or no covid
Classify a certain X-ray as covid, other as no covid


Deep learning is a powerful technique used in artificial intelligence (AI) that enables computers to learn and make decisions, somewhat similar to how our brain works. Here's a simplified explanation of how it works:


Neurons and Neural Networks:
Deep learning is inspired by the human brain, where neurons process information.
Artificial Neural Networks (ANN) are used in deep learning to mimic this process.


Layers of Neurons:
A deep learning model consists of layers of interconnected neurons, arranged like a tower (input layer at the bottom, output layer on top).
These layers are also called hidden layers because their functioning is not directly visible to us.


Input and Output:
The input layer receives data (e.g., images, text, audio) that the model will analyze.
The output layer produces the results or predictions (e.g., image recognition, language translation).


Weights and Biases:
Each connection between neurons has a weight that determines its importance in the decision-making process.
Neurons also have biases, which help them make decisions more accurately.


Learning from Data:
Deep learning requires a massive amount of data for training the model.
During training, the model adjusts its weights and biases by comparing its predictions with the actual outcomes.


Loss Function:
A loss function measures the difference between the predicted results and the actual results.
The goal is to minimize this difference to improve the model's accuracy.


Backpropagation:
It calculates how much each weight and bias contributed to the error and adjusts them accordingly.


Activation Function:
An activation function introduces non-linearity to the model.
It decides whether a neuron should be activated (fire) or not based on the incoming data.


Deep Learning vs. Shallow Learning:
Shallow learning models have only a few hidden layers, limiting their ability to learn complex patterns.
Deep learning models, with multiple hidden layers, can learn intricate patterns, making them more powerful.


Convolutional Neural Networks (CNNs) for Images:
CNNs are specialized deep learning models for image-related tasks.
They use filters to detect features (e.g., edges, textures) and learn hierarchical representations.


Recurrent Neural Networks (RNNs) for Sequences:
RNNs are used for sequence-related tasks, such as language processing and time series prediction.
They have loops to store and utilize information from previous inputs.


Transfer Learning:
Transfer learning allows using pre-trained models for new tasks, saving time and resources.
Models trained on vast datasets (e.g., ImageNet) have learned general features useful for various tasks.


GPUs for Speed:
Training deep learning models is computationally intensive.
Graphics Processing Units (GPUs) accelerate calculations, making training faster.


Applications of Deep Learning:
Deep learning is used in various fields, like computer vision, natural language processing, speech recognition, and autonomous vehicles.
It powers virtual assistants (e.g., Siri, Alexa) and recommendation systems (e.g., Netflix, Spotify).
With its ability to handle large datasets and learn intricate patterns, it has revolutionized numerous industries and continues to shape the future of technology.


Models:
LLMs
Large Language Models (LLMs) are the first type of models we cover. These models take a text string as input, and return a text string as output.
Chat Models
Chat Models are the second type of models we cover. These models are usually backed by a language model, but their APIs are more structured. Specifically, these models take a list of Chat Messages as input, and return a Chat Message.
Text Embedding Models
The third type of models we cover are text embedding models. These models take text as input and return a list of floats.


Prompt:  What’s passed to the underlying model
Chains: LLMChain, which combines a PromptTemplate, a Model, and Guardrails to take user input, format it accordingly, pass it to the model and get a response, and then validate and fix (if necessary) the model output.
Memory: Memory is the concept of storing and retrieving data in the process of a conversation. There are two main methods:
1. Based on input, fetch any relevant pieces of data
2. Based on the input and output, update state accordingly


Indexes: Indexes refer to ways to structure documents so that LLMs can best interact with them
Agents & Tools:
Tools
How language models interact with other resources.
Agents
The language model that drives decision making.


Langchain:
It connects to the AI models you want to use, links them to outside sources


Agent:
LangChain provides agents that have access to a suite of tools. Depending on the user’s input, an agent can decide which tools to call.
All of this means that LangChain makes it possible for developers to build remarkably powerful applications by combining LLMs with other sources of computation and knowledge.


Embeddings: kind of like a wrapper for other modules


VectorStores: 
- most common ways to store and search over unstructured data
- Retrieve embedding vectors that are most similar


Open AI API: gives access to the open ai features in code


Query: has to answer the query along with the resources and references
No need to upload files from the web interface for the web api bot.


Evaluation: Evaluating generative models is challenging with traditional metrics. LangChain helps by providing prompts and chains to assess models using LLMs themselves.


Modular and Flexible Approach:
LangChain's modular approach allows developers to choose the appropriate model for their use case and leverage the provided components to build applications.
It empowers developers with components like prompt templates, output parsers, indexes, retrievers, chat message history, and agents.


Creating Custom Solutions:
By understanding core concepts and components, developers can tailor custom solutions to meet specific needs.
LangChain's adaptability and ease of use make it an invaluable tool for unlocking the full potential of language models.


1. Accessing the API:


Developers can access the OpenAI API by making HTTP requests to their servers.
These requests contain data, such as text, on which the API performs language-related tasks.


Understanding the artificial neural network(ATT), An information processing unit inspired by biological circuits. 3 main boxes of category Input -> hidden units -> Output units. The total number of layers, level of nodes between the inputs and outputs, the number of neurons per architecture define the arch. 


Singlelayer (SLP) and Multilayer perceptron (MLP). 
Neurons memories consist of a vector of weights. Calculation is done by multiplying the sum of the input vectors each value by the corresponding elements of the weight vector. Displayed output is the input of the activation function. 
SLP is a feedforward network based on a threshold transfer function. Can only classify linearly separable cases with a binary target. 


Activation functions make the decision making of the neural network. Calculates the net output of the neural node. Also called a binary step function. 
1 when passing the threshold limit, 0 when not. 
A neurons activation function dictates whether it should be turned off or on. Eg, Sigmoid (1 / (e^-z))


Algorithm initial weights on the SLP are assigned randomly as there is no prior knowledge. SLP sums all the weighted output, if answer is above the threshold 1, else 0.